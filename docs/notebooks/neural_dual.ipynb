{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning the Kantorovich Dual using Input Convex Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/bunnech/Documents/PhD/Projects/ott\n"
     ]
    }
   ],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bunnech/miniforge3/envs/jko/lib/python3.9/site-packages/jax/_src/lib/__init__.py:33: UserWarning: JAX on Mac ARM machines is experimental and minimally tested. Please see https://github.com/google/jax/issues/5501 in the event of problems.\n",
      "  warnings.warn(\"JAX on Mac ARM machines is experimental and minimally tested. \"\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import IterableDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from ott.tools.sinkhorn_divergence import sinkhorn_divergence\n",
    "from ott.geometry import pointcloud\n",
    "from ott.core.neuraldual import NeuralDualSolver, NeuralDual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ot_map(state, source, target):\n",
    "    \"\"\"Plot data and learned optimal transport map.\"\"\"\n",
    "\n",
    "    def draw_arrows(a, b):\n",
    "        plt.arrow(a[0], a[1], b[0] - a[0], b[1] - a[1],\n",
    "                  color=[0.5, 0.5, 1], alpha=0.3)\n",
    "\n",
    "    plt.close('all')\n",
    "\n",
    "    grad_state_s = jax.vmap(lambda x: jax.grad(state.apply_fn, argnums=1)(\n",
    "            {'params': state.params}, x))(source)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    ax.scatter(target[:, 0], target[:, 1], color='#A7BED3',\n",
    "               alpha=0.5, label=r'$x$')\n",
    "    ax.scatter(source[:, 0], source[:, 1], color='#1A254B',\n",
    "               alpha=0.5, label=r'$y$')\n",
    "\n",
    "    ax.scatter(grad_state_s[:, 0], grad_state_s[:, 1], color='#F2545B',\n",
    "               alpha=0.5, label=r'$\\nabla g(y)$')\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    for i in range(source.shape[0]):\n",
    "        draw_arrows(source[i, :], grad_state_s[i, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def sinkhorn_loss(x, y, epsilon=0.1, power=2.0):\n",
    "    \"\"\"Computes transport between (x, a) and (y, b) via Sinkhorn algorithm.\"\"\"\n",
    "    a = jnp.ones(len(x)) / len(x)\n",
    "    b = jnp.ones(len(y)) / len(y)\n",
    "\n",
    "    sdiv = sinkhorn_divergence(pointcloud.PointCloud, x, y, power=power,\n",
    "                               epsilon=epsilon, a=a, b=b, static_b=False,\n",
    "                               sinkhorn_kwargs={'threshold': 1e-2,\n",
    "                                                'tau_a': 0.95, 'tau_b': 0.95})\n",
    "    return sdiv.divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Training and Validation Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyDataset(IterableDataset):\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.create_sample_generators()\n",
    "\n",
    "    def create_sample_generators(self, scale=5.0, variance=0.5):\n",
    "        # given name of dataset, select centers\n",
    "        if self.name == \"simple\":\n",
    "            centers = np.array([0, 0])\n",
    "\n",
    "        elif self.name == \"circle\":\n",
    "            centers = np.array(\n",
    "                [\n",
    "                    (1, 0),\n",
    "                    (-1, 0),\n",
    "                    (0, 1),\n",
    "                    (0, -1),\n",
    "                    (1.0 / np.sqrt(2), 1.0 / np.sqrt(2)),\n",
    "                    (1.0 / np.sqrt(2), -1.0 / np.sqrt(2)),\n",
    "                    (-1.0 / np.sqrt(2), 1.0 / np.sqrt(2)),\n",
    "                    (-1.0 / np.sqrt(2), -1.0 / np.sqrt(2)),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        elif self.name == \"square_five\":\n",
    "            centers = np.array([[0, 0], [1, 1], [-1, 1], [-1, -1], [1, -1]])\n",
    "\n",
    "        elif self.name == \"square_four\":\n",
    "            centers = np.array([[1, 0], [0, 1], [-1, 0], [0, -1]])\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "        # create generator which randomly picks center and adds noise\n",
    "        centers = scale * centers\n",
    "        while True:\n",
    "            center = centers[np.random.choice(len(centers))]\n",
    "            point = center + variance**2 * np.random.randn(2)\n",
    "\n",
    "            yield point\n",
    "\n",
    "\n",
    "def load_toy_data(name_source: str,\n",
    "                  name_target: str,\n",
    "                  batch_size: int = 256,\n",
    "                  valid_batch_size: int = 1024):\n",
    "    dataloaders = (\n",
    "      iter(DataLoader(ToyDataset(name_source), batch_size=batch_size)),\n",
    "      iter(DataLoader(ToyDataset(name_target), batch_size=batch_size)),\n",
    "      iter(DataLoader(ToyDataset(name_source), batch_size=valid_batch_size)),\n",
    "      iter(DataLoader(ToyDataset(name_target), batch_size=valid_batch_size)),\n",
    "    )\n",
    "    input_dim = 2\n",
    "    return dataloaders, input_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve Neural Dual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(dataloader_source, dataloader_target, _, _), input_dim = load_toy_data('simple', 'circle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
      " 47%|█████████████████▊                    | 46957/100000 [45:52<52:27, 16.85it/s]"
     ]
    }
   ],
   "source": [
    "neural_dual_solver = NeuralDualSolver(\n",
    "    input_dim=input_dim, num_train_iters=100000)\n",
    "neural_dual = neural_dual_solver(\n",
    "    dataloader_source, dataloader_target, dataloader_source, dataloader_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Neural Dual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = next(dataloader_source).numpy()\n",
    "data_target = next(dataloader_target).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ot_map(neural_dual.g, data_source, data_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_target = neural_dual.transport(data_source, 'g')\n",
    "print(f'Sinkhorn distance between predictions and data samples: {sinkhorn_loss(pred_target, data_target)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_source = neural_dual.transport(data_target, 'f')\n",
    "print(f'Sinkhorn distance between predictions and data samples: {sinkhorn_loss(pred_source, data_source)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dual_dist = neural_dual.distance(data_source, data_target)\n",
    "print(f'Neural dual distance between source and target data: {dual_dist}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b37caf44d0318b4f4d9ee96c84a0e4fe372b1526393be3417b3365184e480b09"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('jko')",
   "language": "python",
   "name": "python397jvsc74a57bd0b37caf44d0318b4f4d9ee96c84a0e4fe372b1526393be3417b3365184e480b09"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
